{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers<4.25.0,>=4.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/e9/c2b4c823b3959d475a570c1bd2df4125478e2e37b96fb967a87933ae7134/transformers-4.18.0-py3-none-any.whl (4.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.0MB 288kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.6/site-packages (from transformers<4.25.0,>=4.13.0) (2023.8.8)\n",
      "Collecting sacremoses (from transformers<4.25.0,>=4.13.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/78/fef8d089db5b97546fd6d1ff2e813b8544e85670bf3a8c378c9d0250b98d/sacremoses-0.0.53.tar.gz (880kB)\n",
      "\u001b[K    100% |████████████████████████████████| 880kB 721kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers<4.25.0,>=4.13.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/57/da0cb8e40437f88630769164a66afec8af294ff686661497b6c88bc08556/tokenizers-0.12.1.tar.gz (220kB)\n",
      "\u001b[K    100% |████████████████████████████████| 225kB 139kB/s ta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.6/site-packages (from transformers<4.25.0,>=4.13.0) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.6/site-packages (from transformers<4.25.0,>=4.13.0) (21.3)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.6/site-packages (from transformers<4.25.0,>=4.13.0) (3.4.1)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers<4.25.0,>=4.13.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/df/1b454741459f6ce75f86534bdad42ca17291b14a83066695f7d2c676e16c/huggingface_hub-0.4.0-py3-none-any.whl (67kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 114kB/s a 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in ./venv/lib/python3.6/site-packages (from transformers<4.25.0,>=4.13.0) (4.8.3)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in ./venv/lib/python3.6/site-packages (from transformers<4.25.0,>=4.13.0) (0.8)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.6/site-packages (from transformers<4.25.0,>=4.13.0) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.6/site-packages (from transformers<4.25.0,>=4.13.0) (1.19.5)\n",
      "Collecting pyyaml>=5.1 (from transformers<4.25.0,>=4.13.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/e5/af35f7ea75cf72f2cd079c95ee16797de7cd71f29ea7c68ae5ce7be1eda0/PyYAML-6.0.1.tar.gz (125kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 381kB/s ta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in ./venv/lib/python3.6/site-packages (from sacremoses->transformers<4.25.0,>=4.13.0) (1.17.0)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.6/site-packages (from sacremoses->transformers<4.25.0,>=4.13.0) (8.0.4)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.6/site-packages (from sacremoses->transformers<4.25.0,>=4.13.0) (1.1.1)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.7\" in ./venv/lib/python3.6/site-packages (from tqdm>=4.27->transformers<4.25.0,>=4.13.0) (5.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./venv/lib/python3.6/site-packages (from packaging>=20.0->transformers<4.25.0,>=4.13.0) (3.1.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers<4.25.0,>=4.13.0) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./venv/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers<4.25.0,>=4.13.0) (3.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.6/site-packages (from requests->transformers<4.25.0,>=4.13.0) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.6/site-packages (from requests->transformers<4.25.0,>=4.13.0) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./venv/lib/python3.6/site-packages (from requests->transformers<4.25.0,>=4.13.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./venv/lib/python3.6/site-packages (from requests->transformers<4.25.0,>=4.13.0) (3.10)\n",
      "Building wheels for collected packages: sacremoses, tokenizers, pyyaml\n",
      "  Running setup.py bdist_wheel for sacremoses ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/adam/.cache/pip/wheels/56/d5/b2/bc878b2bbddfbcc8fd62ca73c4fd842bd28c1fd3dbdf424c74\n",
      "  Running setup.py bdist_wheel for tokenizers ... \u001b[?25lerror\n",
      "  Complete output from command /media/Data/projects/chatbot/healthchat/venv/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-lwh5sq8g/tokenizers/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/pip-wheel-_soq8umb --python-tag cp36:\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.6\n",
      "  creating build/lib.linux-x86_64-3.6/tokenizers\n",
      "  copying py_src/tokenizers/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers\n",
      "  creating build/lib.linux-x86_64-3.6/tokenizers/models\n",
      "  copying py_src/tokenizers/models/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/models\n",
      "  creating build/lib.linux-x86_64-3.6/tokenizers/decoders\n",
      "  copying py_src/tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/decoders\n",
      "  creating build/lib.linux-x86_64-3.6/tokenizers/normalizers\n",
      "  copying py_src/tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/normalizers\n",
      "  creating build/lib.linux-x86_64-3.6/tokenizers/pre_tokenizers\n",
      "  copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/pre_tokenizers\n",
      "  creating build/lib.linux-x86_64-3.6/tokenizers/processors\n",
      "  copying py_src/tokenizers/processors/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/processors\n",
      "  creating build/lib.linux-x86_64-3.6/tokenizers/trainers\n",
      "  copying py_src/tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/trainers\n",
      "  creating build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "  creating build/lib.linux-x86_64-3.6/tokenizers/tools\n",
      "  copying py_src/tokenizers/tools/visualizer.py -> build/lib.linux-x86_64-3.6/tokenizers/tools\n",
      "  copying py_src/tokenizers/tools/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/tools\n",
      "  copying py_src/tokenizers/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers\n",
      "  copying py_src/tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/models\n",
      "  copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/decoders\n",
      "  copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/normalizers\n",
      "  copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/pre_tokenizers\n",
      "  copying py_src/tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/processors\n",
      "  copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/trainers\n",
      "  copying py_src/tokenizers/tools/visualizer-styles.css -> build/lib.linux-x86_64-3.6/tokenizers/tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for tokenizers\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for tokenizers\n",
      "  Complete output from command /media/Data/projects/chatbot/healthchat/venv/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-lwh5sq8g/tokenizers/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" clean --all:\n",
      "  running clean\n",
      "  removing 'build/lib.linux-x86_64-3.6' (and everything under it)\n",
      "  'build/bdist.linux-x86_64' does not exist -- can't clean it\n",
      "  'build/scripts-3.6' does not exist -- can't clean it\n",
      "  removing 'build'\n",
      "  running clean_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed cleaning build dir for tokenizers\u001b[0m\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/adam/.cache/pip/wheels/e6/c6/ef/4e8ee93f1b79fc90562f1600d47189799f8213023d9dadafa2\n",
      "Successfully built sacremoses pyyaml\n",
      "Failed to build tokenizers\n",
      "Installing collected packages: sacremoses, tokenizers, pyyaml, huggingface-hub, transformers\n",
      "  Running setup.py install for tokenizers ... \u001b[?25lerror\n",
      "    Complete output from command /media/Data/projects/chatbot/healthchat/venv/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-lwh5sq8g/tokenizers/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-ws8tu0nn/install-record.txt --single-version-externally-managed --compile --install-headers /media/Data/projects/chatbot/healthchat/venv/include/site/python3.6/tokenizers:\n",
      "    running install\n",
      "    /tmp/pip-build-env-cugzecyv/lib/python3.6/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "      setuptools.SetuptoolsDeprecationWarning,\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.6\n",
      "    creating build/lib.linux-x86_64-3.6/tokenizers\n",
      "    copying py_src/tokenizers/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers\n",
      "    creating build/lib.linux-x86_64-3.6/tokenizers/models\n",
      "    copying py_src/tokenizers/models/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/models\n",
      "    creating build/lib.linux-x86_64-3.6/tokenizers/decoders\n",
      "    copying py_src/tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/decoders\n",
      "    creating build/lib.linux-x86_64-3.6/tokenizers/normalizers\n",
      "    copying py_src/tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/normalizers\n",
      "    creating build/lib.linux-x86_64-3.6/tokenizers/pre_tokenizers\n",
      "    copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/pre_tokenizers\n",
      "    creating build/lib.linux-x86_64-3.6/tokenizers/processors\n",
      "    copying py_src/tokenizers/processors/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/processors\n",
      "    creating build/lib.linux-x86_64-3.6/tokenizers/trainers\n",
      "    copying py_src/tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/trainers\n",
      "    creating build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "    copying py_src/tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "    copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "    copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "    copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "    copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "    copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "    copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-3.6/tokenizers/implementations\n",
      "    creating build/lib.linux-x86_64-3.6/tokenizers/tools\n",
      "    copying py_src/tokenizers/tools/visualizer.py -> build/lib.linux-x86_64-3.6/tokenizers/tools\n",
      "    copying py_src/tokenizers/tools/__init__.py -> build/lib.linux-x86_64-3.6/tokenizers/tools\n",
      "    copying py_src/tokenizers/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers\n",
      "    copying py_src/tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/models\n",
      "    copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/decoders\n",
      "    copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/normalizers\n",
      "    copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/pre_tokenizers\n",
      "    copying py_src/tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/processors\n",
      "    copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-3.6/tokenizers/trainers\n",
      "    copying py_src/tokenizers/tools/visualizer-styles.css -> build/lib.linux-x86_64-3.6/tokenizers/tools\n",
      "    running build_ext\n",
      "    running build_rust\n",
      "    error: can't find Rust compiler\n",
      "    \n",
      "    If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "    \n",
      "    To update pip, run:\n",
      "    \n",
      "        pip install --upgrade pip\n",
      "    \n",
      "    and then retry package installation.\n",
      "    \n",
      "    If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"/media/Data/projects/chatbot/healthchat/venv/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-lwh5sq8g/tokenizers/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-ws8tu0nn/install-record.txt --single-version-externally-managed --compile --install-headers /media/Data/projects/chatbot/healthchat/venv/include/site/python3.6/tokenizers\" failed with error code 1 in /tmp/pip-install-lwh5sq8g/tokenizers/\u001b[0m\n",
      "\u001b[33mYou are using pip version 18.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25hTraceback (most recent call last):\n",
      "  File \"/home/adam/.pyenv/versions/3.6.15/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/adam/.pyenv/versions/3.6.15/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/Data/projects/chatbot/healthchat/venv/lib/python3.6/site-packages/deeppavlov/__main__.py\", line 4, in <module>\n",
      "    main()\n",
      "  File \"/media/Data/projects/chatbot/healthchat/venv/lib/python3.6/site-packages/deeppavlov/deep.py\", line 62, in main\n",
      "    install_from_config(pipeline_config_path)\n",
      "  File \"/media/Data/projects/chatbot/healthchat/venv/lib/python3.6/site-packages/deeppavlov/utils/pip_wrapper/pip_wrapper.py\", line 71, in install_from_config\n",
      "    install(r)\n",
      "  File \"/media/Data/projects/chatbot/healthchat/venv/lib/python3.6/site-packages/deeppavlov/utils/pip_wrapper/pip_wrapper.py\", line 38, in install\n",
      "    env=os.environ.copy())\n",
      "  File \"/home/adam/.pyenv/versions/3.6.15/lib/python3.6/subprocess.py\", line 311, in check_call\n",
      "    raise CalledProcessError(retcode, cmd)\n",
      "subprocess.CalledProcessError: Command '['/media/Data/projects/chatbot/healthchat/venv/bin/python', '-m', 'pip', 'install', 'transformers>=4.13.0,<4.25.0;python_version<\"3.8\"']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install squad_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/media/Data/projects/chatbot/healthchat/venv/bin/python', '-m', 'pip', 'install', 'transformers>=4.13.0,<4.25.0;python_version<\"3.8\"']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-25c6079152ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeeppavlov\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'squad_bert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/projects/chatbot/healthchat/venv/lib/python3.6/site-packages/deeppavlov/core/commands/infer.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(config, mode, load_trained, install, download)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minstall\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0minstall_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdeep_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/projects/chatbot/healthchat/venv/lib/python3.6/site-packages/deeppavlov/utils/pip_wrapper/pip_wrapper.py\u001b[0m in \u001b[0;36minstall_from_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequirements\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/Data/projects/chatbot/healthchat/venv/lib/python3.6/site-packages/deeppavlov/utils/pip_wrapper/pip_wrapper.py\u001b[0m in \u001b[0;36minstall\u001b[0;34m(*packages)\u001b[0m\n\u001b[1;32m     36\u001b[0m     result = subprocess.check_call([sys.executable, '-m', 'pip', 'install',\n\u001b[1;32m     37\u001b[0m                                     *[re.sub(r'\\s', '', package) for package in packages]],\n\u001b[0;32m---> 38\u001b[0;31m                                    env=os.environ.copy())\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.15/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/media/Data/projects/chatbot/healthchat/venv/bin/python', '-m', 'pip', 'install', 'transformers>=4.13.0,<4.25.0;python_version<\"3.8\"']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deeppavlov import build_model\n",
    "\n",
    "model = build_model('squad_bert', download=True, install=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-926e7b7a84da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model(['In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail… Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud. Short, intense periods of rain in scattered locations are called \"showers\".'], \n\u001b[0m\u001b[1;32m      2\u001b[0m  ['Where do water droplets collide with ice crystals to form precipitation?'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model(['In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail… Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud. Short, intense periods of rain in scattered locations are called \"showers\".'], \n",
    " ['Where do water droplets collide with ice crystals to form precipitation?'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
